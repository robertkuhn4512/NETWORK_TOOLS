"""
Device discovery endpoints
ssh discovery
snmp v2
snmp v3
"""

"""
Import any custom utilities
"""
from app.network_utilities.icmp_check import pingOk

"""
Regular includes / imports etc.
"""
from uuid import uuid4

from starlette.status import HTTP_400_BAD_REQUEST, HTTP_403_FORBIDDEN
from fastapi import APIRouter, Depends, HTTPException, Request, BackgroundTasks
from pydantic import BaseModel, Field
from app.security.auth import UserContext, get_current_user, require_roles

from app.database import database
from app.database_queries.postgres_insert_queries import (insert_app_backend_tracking)

from app.celery_app import celery_app

from app.shared_functions.helpers.helpers import (
    user_display,
    scrub_secrets,
    _reserve_job_row_queued,
    _attach_task_id,
    expand_ipv4_targets_max_24,
    _mark_job_failed_enqueue
)

import hashlib
import json
import logging
import ipaddress

logger = logging.getLogger("app.device_discovery")

router = APIRouter(
    prefix="/device_discovery",
    tags=["device_discovery"],
    dependencies=[Depends(get_current_user)]
)


"""
Classes
"""

class DiscoveryTarget(BaseModel):
    ipv4_address: str | None = Field(default=None, example="10.0.0.0/32")
    task: str | None = Field(default=None, example="ssh | snmpv2 | snmpv3")
    bypass_icmp: bool | None = Field(default=False, example="True: Bypass ICMP Check. The server will not attempt to ping the device when starting discovery.Otherwise if ICMP fails, the server will stop discovery.")

"""

NOTES:
There is a test script built to post to this endpoint if you want to use it and not setup
something in a different program. Change the values for the credentials to fit your setup.

Instructions on how to use are at the top of the file. 

backend/build_scripts/documentation/fastapi/test_scripts/test_fastapi_keycloak_cc.sh

"""

"""
Utility functions
"""

def make_dedupe_key(*, job_name: str, target_ip: str, payload: dict) -> str:
    # include only fields that should define uniqueness
    basis = {
        "job_name": job_name,
        "target_ip": target_ip,
        "task": payload.get("task") or "",
        "bypass_icmp": bool(payload.get("bypass_icmp", False)),
    }
    return hashlib.sha256(json.dumps(basis, sort_keys=True).encode("utf-8")).hexdigest()


@router.post("/start_device_discovery", summary="Enqueue device discovery jobs (CIDR max /24)", status_code=200)
async def start_device_discovery(
    payload: DiscoveryTarget,
    request: Request,
    user: UserContext = Depends(get_current_user),
):
    RETURN_PREVIEW = 25  # how many per-IP jobs to include in the response preview
    required = {"fastapi_client", "device_discovery_user"}
    if not required.intersection(set(user.roles or [])):
        raise HTTPException(status_code=HTTP_403_FORBIDDEN, detail="Insufficient role")

    if not payload.ipv4_address:
        raise HTTPException(status_code=HTTP_400_BAD_REQUEST, detail="ipv4_address is required")

    try:
        cidr_norm, targets = expand_ipv4_targets_max_24(payload.ipv4_address)
    except ValueError as exc:
        raise HTTPException(status_code=HTTP_400_BAD_REQUEST, detail=str(exc))

    requested_by = user_display(user)
    batch_id = str(uuid4())
    job_name = "device_discovery.start_device_discovery"

    enqueued = []
    skipped = []

    scrubbed_payload = scrub_secrets(payload.model_dump())

    for target_ip in targets:
        dedupe_key = make_dedupe_key(job_name=job_name, target_ip=target_ip, payload=scrubbed_payload)

        meta = {
            "batch_id": batch_id,
            "job_id": None,  # will be set from reserve result
            "dedupe_key": dedupe_key,
            "route": str(request.url.path),
            "requested_by": requested_by,
            "azp": getattr(user, "azp", None),
            "roles": user.roles or [],
            "target_cidr": cidr_norm,
            "target_ip": target_ip,
            "payload": scrubbed_payload,
        }

        # Reserve first (dedupe guarantee)
        reserve = await _reserve_job_row_queued(
            job_name=job_name,
            dedupe_key=dedupe_key,
            request_payload=meta,          # safe: scrubbed
            correlation_id=batch_id,       # optional, but nice for querying batches
        )

        if reserve.get("error"):
            skipped.append({"target_ip": target_ip, "error": reserve["error"]})
            continue

        meta["job_id"] = reserve["job_id"]

        if not reserve["created"]:
            skipped.append({
                "target_ip": target_ip,
                "job_id": reserve["job_id"],
                "celery_task_id": reserve.get("task_id"),
                "status": reserve.get("status"),
            })
            continue

        # Only enqueue if we successfully reserved a new row
        # (reserve should return a non-null task_id if your DB column is NOT NULL)
        try:
            celery_task_id = reserve["task_id"]  # <- pre-generated by _reserve_job_row_queued
            meta["job_id"] = reserve["job_id"]  # already set above, but harmless

            celery_app.send_task(
                job_name,
                args=[meta],
                task_id=celery_task_id,  # <- key point: Celery uses the same ID your DB row already has
            )

            enqueued.append({
                "target_ip": target_ip,
                "job_id": reserve["job_id"],
                "celery_task_id": celery_task_id,
            })

        except Exception as exc:
            await _mark_job_failed_enqueue(
                job_id=reserve["job_id"],
                error_message=str(exc),
            )
            skipped.append({"target_ip": target_ip, "job_id": reserve["job_id"], "error": "enqueue_failed"})
            continue
    await insert_app_backend_tracking(
        database=database,
        route=request.url.path,
        information={
            "event": "device_discovery_batch_enqueued",
            "batch_id": batch_id,
            "requested_by": requested_by,
            "azp": getattr(user, "azp", None),
            "roles": user.roles or [],
            "target_cidr": cidr_norm,
            "targets_count": len(targets),
            "enqueued_count": len(enqueued),
            "skipped_duplicates_count": len(skipped),
        },
    )

    return {
        "detail": {
            "batch_id": batch_id,
            "job_name": job_name,
            "target_cidr": cidr_norm,
            "targets_count": len(targets),
            "enqueued_count": len(enqueued),
            "skipped_duplicates_count": len(skipped),
            "enqueued_preview": enqueued[:RETURN_PREVIEW],
            "skipped_preview": skipped[:RETURN_PREVIEW],
            "preview_truncated": (len(enqueued) > RETURN_PREVIEW) or (len(skipped) > RETURN_PREVIEW),
        }
    }